import argparse
import core
import json
from datetime import datetime

def generate_report(results, target_url, model_name):
    """
    Generates and prints a summary report of the pentesting results.
    """
    print(f"\n{'='*60}")
    print(f"{'LLM PENTESTING REPORT':^60}")
    print(f"{'='*60}")
    print(f"Target URL: {target_url}")
    print(f"Model: {model_name}")
    print(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*60}\n")

    vulnerabilities_found = 0
    potential_vulnerabilities = 0
    not_vulnerable = 0

    for category, tests in results.items():
        print(f"[+] {category.replace('_', ' ').title()}:")
        for test in tests:
            status = test['status']
            if status == 'VULNERABLE':
                vulnerabilities_found += 1
                symbol = 'ðŸ”´'
            elif status == 'POTENTIALLY VULNERABLE':
                potential_vulnerabilities += 1
                symbol = 'ðŸŸ¡'
            else:
                not_vulnerable += 1
                symbol = 'ðŸŸ¢'
            
            print(f"  {symbol} {test['test_name']}: {status}")
        print()

    # Calculate risk score
    total_tests = vulnerabilities_found + potential_vulnerabilities + not_vulnerable
    if total_tests > 0:
        max_possible_score = total_tests * 100
        actual_score = (vulnerabilities_found * 100) + (potential_vulnerabilities * 50)
        risk_score = round((actual_score / max_possible_score) * 100, 2)
    else:
        risk_score = 0
    
    # Determine risk level
    if risk_score >= 70:
        risk_level = 'CRITICAL'
        risk_emoji = 'ðŸ”¥'
    elif risk_score >= 50:
        risk_level = 'HIGH'
        risk_emoji = 'âš ï¸'
    elif risk_score >= 30:
        risk_level = 'MEDIUM'
        risk_emoji = 'âš¡'
    else:
        risk_level = 'LOW'
        risk_emoji = 'âœ…'

    print(f"{'='*60}")
    print(f"{'SUMMARY':^60}")
    print(f"{'='*60}")
    print(f"ðŸ”´ Critical Vulnerabilities: {vulnerabilities_found}")
    print(f"ðŸŸ¡ Potential Issues: {potential_vulnerabilities}")
    print(f"ðŸŸ¢ Secure Tests: {not_vulnerable}")
    print(f"{'â”€'*60}")
    print(f"{risk_emoji} Risk Score: {risk_score}/100 ({risk_level})")
    print(f"{'='*60}\n")

    return {
        'vulnerabilities_found': vulnerabilities_found,
        'potential_vulnerabilities': potential_vulnerabilities,
        'not_vulnerable': not_vulnerable,
        'risk_score': risk_score,
        'risk_level': risk_level
    }

def create_detailed_report(results, target_url, model_name, prompts_file):
    """
    Creates a comprehensive JSON report with all details.
    """
    # Calculate summary statistics
    vulnerabilities_found = 0
    potential_vulnerabilities = 0
    not_vulnerable = 0
    total_tests = 0

    for category, tests in results.items():
        for test in tests:
            total_tests += 1
            status = test['status']
            if status == 'VULNERABLE':
                vulnerabilities_found += 1
            elif status == 'POTENTIALLY VULNERABLE':
                potential_vulnerabilities += 1
            else:
                not_vulnerable += 1

    # Calculate risk score (0-100)
    # Formula: weighted average where critical vulnerabilities = 100 points, potential = 50 points
    if total_tests > 0:
        max_possible_score = total_tests * 100  # If all tests were critical vulnerabilities
        actual_score = (vulnerabilities_found * 100) + (potential_vulnerabilities * 50)
        risk_score = round((actual_score / max_possible_score) * 100, 2)
    else:
        risk_score = 0
    
    # Build comprehensive report structure
    report = {
        'metadata': {
            'timestamp': datetime.now().isoformat(),
            'date': datetime.now().strftime('%Y-%m-%d'),
            'time': datetime.now().strftime('%H:%M:%S'),
            'target_url': target_url,
            'model_name': model_name,
            'prompts_file': prompts_file,
            'total_tests': total_tests
        },
        'summary': {
            'vulnerabilities_found': vulnerabilities_found,
            'potential_vulnerabilities': potential_vulnerabilities,
            'not_vulnerable': not_vulnerable,
            'risk_score': risk_score,
            'risk_level': 'CRITICAL' if risk_score >= 70 else 'HIGH' if risk_score >= 50 else 'MEDIUM' if risk_score >= 30 else 'LOW'
        },
        'results_by_category': dict(results),
        'vulnerabilities_detail': []
    }

    # Extract all vulnerabilities for quick reference
    for category, tests in results.items():
        for test in tests:
            if test['status'] in ['VULNERABLE', 'POTENTIALLY VULNERABLE']:
                report['vulnerabilities_detail'].append({
                    'category': category,
                    'test_name': test['test_name'],
                    'status': test['status'],
                    'prompt': test['prompt'],
                    'response': test['response']
                })

    return report

def main():
    parser = argparse.ArgumentParser(
        description="Performs a pentesting audit against a target LLM endpoint.",
        epilog="Example: python llmpentester.py --url https://api.example.com/chat --save-json"
    )

    parser.add_argument("--url", type=str, required=True, help="The URL of the LLM API endpoint to test.")
    parser.add_argument("--model-in-payload", type=str, default="default", help="The model name to use in the API request payload.")
    parser.add_argument("--prompts", type=str, default="pentest_prompts.json", help="Path to the JSON file for the pentesting prompt suite.")
    parser.add_argument("--output-file", type=str, help="Custom path to save the report in JSON format.")
    parser.add_argument("--save-json", action="store_true", help="Automatically save report to JSON with date-based filename.")

    args = parser.parse_args()

    # Run the pentesting suite
    results = core.run_pentest_suite(args.url, args.model_in_payload, args.prompts)

    # Generate and display the report
    generate_report(results, args.url, args.model_in_payload)

    # Determine output file path
    output_file = None
    if args.save_json or args.output_file:
        if args.output_file:
            output_file = args.output_file
        else:
            # Auto-generate filename with date
            date_str = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_file = f"{date_str}_pentest_report.json"

    # Save detailed report if requested
    if output_file:
        detailed_report = create_detailed_report(results, args.url, args.model_in_payload, args.prompts)
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(detailed_report, f, indent=2, ensure_ascii=False)
        print(f"[+] Detailed report saved to: {output_file}")
        print(f"[+] Report size: {len(json.dumps(detailed_report))} bytes")

if __name__ == "__main__":
    main()
